{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch as tc\n",
    "import torchvision as tv\n",
    "import torch.utils.data as Data\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd\n",
    "1. define tensor with \"requires_grad=True\"\n",
    "2. write formula\n",
    "3. call .backward()\n",
    "Example: gradiant on $B=x^TAx$, $\\frac{dB}{dx}=(A+A^T)x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1],\n",
      "        [ 2],\n",
      "        [ 3]])\n",
      "tensor([[ 1,  2,  3],\n",
      "        [ 2,  4,  4],\n",
      "        [ 3,  4,  5]])\n"
     ]
    }
   ],
   "source": [
    "x = tc.tensor([[1],[2],[3]], requires_grad=True)\n",
    "A = tc.tensor([[1,2,3],[2,4,4],[3,4,5]])\n",
    "print(x)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 136]])\n",
      "tensor([[ 28],\n",
      "        [ 44],\n",
      "        [ 52]])\n",
      "tensor([[ 28],\n",
      "        [ 44],\n",
      "        [ 52]])\n"
     ]
    }
   ],
   "source": [
    "B = x.t().mm(A).mm(x)\n",
    "print(B)\n",
    "# x.grad.zero_()\n",
    "B.backward()\n",
    "print(x.grad)\n",
    "actual_grad = (A+A.t()).mm(x)\n",
    "print( actual_grad )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression using pytorch\n",
    "What do we do:\n",
    "```python\n",
    "step 0: load data and parameter\n",
    "\n",
    "step 1: def forward(X):\n",
    "            # pass\n",
    "            return y_pred\n",
    "step 2: def loss_fn(y_pred, y_target):\n",
    "            # pass\n",
    "            return loss\n",
    "step 3: def update(loss,W_old)ï¼š\n",
    "            # pass:\n",
    "            return W_new\n",
    "```\n",
    "Done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tc.rand([100,5])\n",
    "y = tc.empty(100, dtype=tc.long).random_(3)\n",
    "W = tc.rand([5,3],requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5812,  0.4461,  0.5705,  0.5443,  0.8364],\n",
      "        [ 0.0084,  0.3039,  0.7557,  0.4043,  0.2165],\n",
      "        [ 0.4549,  0.5666,  0.9928,  0.6596,  0.8747],\n",
      "        [ 0.4063,  0.8554,  0.1484,  0.3131,  0.8383],\n",
      "        [ 0.8797,  0.5750,  0.4503,  0.9047,  0.4671],\n",
      "        [ 0.9939,  0.5332,  0.2953,  0.0506,  0.4294],\n",
      "        [ 0.5445,  0.9110,  0.8199,  0.2339,  0.1789],\n",
      "        [ 0.3521,  0.3648,  0.9690,  0.5000,  0.2175],\n",
      "        [ 0.9765,  0.9987,  0.5703,  0.4890,  0.0594],\n",
      "        [ 0.8149,  0.7346,  0.0191,  0.2895,  0.1672]])\n",
      "tensor([ 1,  0,  1,  1,  0,  0,  1,  1,  0,  2])\n",
      "tensor([[ 0.8018,  0.2544,  0.5300],\n",
      "        [ 0.2165,  0.4187,  0.3232],\n",
      "        [ 0.5645,  0.0527,  0.2755],\n",
      "        [ 0.7031,  0.3142,  0.7773],\n",
      "        [ 0.4183,  0.9204,  0.1577]])\n"
     ]
    }
   ],
   "source": [
    "print(X[:10])\n",
    "print(y[:10])\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__torch.nn__ includes may classes that act like \"functions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_loss_func = tc.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use his function to calculate the numerial loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_loss = logreg_loss_func(X.mm(W), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The call __.backward()__ to see get the gradiant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.00000e-02 *\n",
       "       [[ 0.5486, -3.7213,  3.1727],\n",
       "        [ 0.8755, -3.2741,  2.3986],\n",
       "        [ 2.6686, -4.9537,  2.2852],\n",
       "        [ 0.6502, -2.3136,  1.6634],\n",
       "        [ 0.4249, -2.4068,  1.9819]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#W.grad.zero_()\n",
    "logreg_loss.backward(retain_graph=True)\n",
    "grad = W.grad\n",
    "grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.8019,  0.2540,  0.5303],\n",
       "        [ 0.2166,  0.4184,  0.3234],\n",
       "        [ 0.5648,  0.0522,  0.2758],\n",
       "        [ 0.7031,  0.3140,  0.7774],\n",
       "        [ 0.4183,  0.9202,  0.1579]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with tc.no_grad():\n",
    "    lr = 0.01\n",
    "    W = W + grad * lr\n",
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we update W, we could see all difficult part are done by pytorch\n",
    "## Encapsulation even more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N, D_in, H, D_out = 64, 1000, 100, 10\n",
    "x = tc.randn(N, D_in)\n",
    "y = tc.randn(N, D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "forward_fn = tc.nn.Sequential(\n",
    "    tc.nn.Linear(D_in, H),\n",
    "    tc.nn.ReLU(),\n",
    "    tc.nn.Linear(H, D_out),\n",
    ")\n",
    "loss_fn = tc.nn.MSELoss(size_average=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0997)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = forward_fn(x)\n",
    "loss = loss_fn(y_pred, y)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.0996840000152588\n",
      "1 1.099530577659607\n",
      "2 1.0993759632110596\n",
      "3 1.0992209911346436\n",
      "4 1.0990670919418335\n",
      "5 1.0989136695861816\n",
      "6 1.0987579822540283\n",
      "7 1.0986045598983765\n",
      "8 1.0984506607055664\n",
      "9 1.0982961654663086\n",
      "10 1.0981428623199463\n",
      "11 1.0979886054992676\n",
      "12 1.097834825515747\n",
      "13 1.0976808071136475\n",
      "14 1.097527265548706\n",
      "15 1.097372055053711\n",
      "16 1.09721839427948\n",
      "17 1.0970653295516968\n",
      "18 1.0969122648239136\n",
      "19 1.096757173538208\n",
      "20 1.096604347229004\n",
      "21 1.0964512825012207\n",
      "22 1.0962964296340942\n",
      "23 1.0961427688598633\n",
      "24 1.0959898233413696\n",
      "25 1.0958373546600342\n",
      "26 1.0956830978393555\n",
      "27 1.0955301523208618\n",
      "28 1.09537672996521\n",
      "29 1.0952231884002686\n",
      "30 1.0950701236724854\n",
      "31 1.0949167013168335\n",
      "32 1.094763994216919\n",
      "33 1.0946112871170044\n",
      "34 1.0944582223892212\n",
      "35 1.0943059921264648\n",
      "36 1.0941516160964966\n",
      "37 1.0939996242523193\n",
      "38 1.0938466787338257\n",
      "39 1.0936943292617798\n",
      "40 1.0935418605804443\n",
      "41 1.0933897495269775\n",
      "42 1.0932366847991943\n",
      "43 1.0930840969085693\n",
      "44 1.0929315090179443\n",
      "45 1.0927791595458984\n",
      "46 1.092626929283142\n",
      "47 1.092474102973938\n",
      "48 1.0923224687576294\n",
      "49 1.092170000076294\n",
      "50 1.0920177698135376\n",
      "51 1.0918653011322021\n",
      "52 1.0917130708694458\n",
      "53 1.091562032699585\n",
      "54 1.09140944480896\n",
      "55 1.0912572145462036\n",
      "56 1.0911054611206055\n",
      "57 1.0909526348114014\n",
      "58 1.0908015966415405\n",
      "59 1.0906490087509155\n",
      "60 1.0904970169067383\n",
      "61 1.090346336364746\n",
      "62 1.090194821357727\n",
      "63 1.0900427103042603\n",
      "64 1.0898910760879517\n",
      "65 1.0897395610809326\n",
      "66 1.0895869731903076\n",
      "67 1.0894356966018677\n",
      "68 1.0892847776412964\n",
      "69 1.0891335010528564\n",
      "70 1.0889818668365479\n",
      "71 1.088830590248108\n",
      "72 1.088679552078247\n",
      "73 1.0885289907455444\n",
      "74 1.088377594947815\n",
      "75 1.0882261991500854\n",
      "76 1.0880744457244873\n",
      "77 1.0879231691360474\n",
      "78 1.0877723693847656\n",
      "79 1.0876212120056152\n",
      "80 1.0874712467193604\n",
      "81 1.0873194932937622\n",
      "82 1.0871691703796387\n",
      "83 1.087018370628357\n",
      "84 1.0868680477142334\n",
      "85 1.086717963218689\n",
      "86 1.0865662097930908\n",
      "87 1.0864152908325195\n",
      "88 1.086264967918396\n",
      "89 1.0861151218414307\n",
      "90 1.0859644412994385\n",
      "91 1.0858142375946045\n",
      "92 1.0856642723083496\n",
      "93 1.0855138301849365\n",
      "94 1.0853636264801025\n",
      "95 1.0852125883102417\n",
      "96 1.085063099861145\n",
      "97 1.0849134922027588\n",
      "98 1.0847628116607666\n",
      "99 1.084612488746643\n",
      "100 1.0844625234603882\n",
      "101 1.0843122005462646\n",
      "102 1.084162712097168\n",
      "103 1.0840119123458862\n",
      "104 1.0838629007339478\n",
      "105 1.083713173866272\n",
      "106 1.0835628509521484\n",
      "107 1.083414077758789\n",
      "108 1.0832643508911133\n",
      "109 1.0831146240234375\n",
      "110 1.0829659700393677\n",
      "111 1.0828170776367188\n",
      "112 1.0826678276062012\n",
      "113 1.0825178623199463\n",
      "114 1.0823683738708496\n",
      "115 1.0822192430496216\n",
      "116 1.08207106590271\n",
      "117 1.0819213390350342\n",
      "118 1.0817712545394897\n",
      "119 1.0816234350204468\n",
      "120 1.0814743041992188\n",
      "121 1.0813257694244385\n",
      "122 1.0811759233474731\n",
      "123 1.0810266733169556\n",
      "124 1.080878496170044\n",
      "125 1.0807301998138428\n",
      "126 1.0805808305740356\n",
      "127 1.0804322957992554\n",
      "128 1.0802829265594482\n",
      "129 1.0801348686218262\n",
      "130 1.0799862146377563\n",
      "131 1.0798372030258179\n",
      "132 1.0796887874603271\n",
      "133 1.079540491104126\n",
      "134 1.0793919563293457\n",
      "135 1.0792429447174072\n",
      "136 1.0790951251983643\n",
      "137 1.0789458751678467\n",
      "138 1.0787971019744873\n",
      "139 1.0786499977111816\n",
      "140 1.0785012245178223\n",
      "141 1.078352928161621\n",
      "142 1.078204870223999\n",
      "143 1.0780569314956665\n",
      "144 1.0779081583023071\n",
      "145 1.0777596235275269\n",
      "146 1.0776119232177734\n",
      "147 1.077463984489441\n",
      "148 1.077315330505371\n",
      "149 1.077167272567749\n",
      "150 1.077019453048706\n",
      "151 1.0768722295761108\n",
      "152 1.0767238140106201\n",
      "153 1.0765759944915771\n",
      "154 1.0764284133911133\n",
      "155 1.076280117034912\n",
      "156 1.076132893562317\n",
      "157 1.075984001159668\n",
      "158 1.0758357048034668\n",
      "159 1.0756890773773193\n",
      "160 1.0755411386489868\n",
      "161 1.0753930807113647\n",
      "162 1.0752453804016113\n",
      "163 1.075099229812622\n",
      "164 1.0749508142471313\n",
      "165 1.0748028755187988\n",
      "166 1.0746557712554932\n",
      "167 1.074507713317871\n",
      "168 1.074360966682434\n",
      "169 1.0742135047912598\n",
      "170 1.0740658044815063\n",
      "171 1.073918342590332\n",
      "172 1.0737712383270264\n",
      "173 1.0736236572265625\n",
      "174 1.0734771490097046\n",
      "175 1.073329210281372\n",
      "176 1.0731823444366455\n",
      "177 1.0730351209640503\n",
      "178 1.0728886127471924\n",
      "179 1.072740912437439\n",
      "180 1.0725948810577393\n",
      "181 1.0724478960037231\n",
      "182 1.072299838066101\n",
      "183 1.0721538066864014\n",
      "184 1.0720065832138062\n",
      "185 1.0718603134155273\n",
      "186 1.0717140436172485\n",
      "187 1.0715659856796265\n",
      "188 1.071420431137085\n",
      "189 1.0712732076644897\n",
      "190 1.0711264610290527\n",
      "191 1.0709807872772217\n",
      "192 1.0708339214324951\n",
      "193 1.070687174797058\n",
      "194 1.070541501045227\n",
      "195 1.0703954696655273\n",
      "196 1.0702478885650635\n",
      "197 1.0701019763946533\n",
      "198 1.069955825805664\n",
      "199 1.0698106288909912\n",
      "200 1.0696643590927124\n",
      "201 1.0695182085037231\n",
      "202 1.0693732500076294\n",
      "203 1.0692274570465088\n",
      "204 1.0690810680389404\n",
      "205 1.0689363479614258\n",
      "206 1.068790316581726\n",
      "207 1.0686458349227905\n",
      "208 1.068499207496643\n",
      "209 1.0683541297912598\n",
      "210 1.068208932876587\n",
      "211 1.0680633783340454\n",
      "212 1.0679190158843994\n",
      "213 1.0677735805511475\n",
      "214 1.0676275491714478\n",
      "215 1.0674833059310913\n",
      "216 1.0673381090164185\n",
      "217 1.0671931505203247\n",
      "218 1.0670483112335205\n",
      "219 1.0669032335281372\n",
      "220 1.066758155822754\n",
      "221 1.0666126012802124\n",
      "222 1.0664684772491455\n",
      "223 1.0663230419158936\n",
      "224 1.0661784410476685\n",
      "225 1.0660346746444702\n",
      "226 1.065889835357666\n",
      "227 1.0657446384429932\n",
      "228 1.0656012296676636\n",
      "229 1.0654562711715698\n",
      "230 1.0653119087219238\n",
      "231 1.0651663541793823\n",
      "232 1.0650231838226318\n",
      "233 1.0648778676986694\n",
      "234 1.0647343397140503\n",
      "235 1.0645887851715088\n",
      "236 1.0644451379776\n",
      "237 1.0643008947372437\n",
      "238 1.0641565322875977\n",
      "239 1.0640122890472412\n",
      "240 1.0638678073883057\n",
      "241 1.0637242794036865\n",
      "242 1.0635792016983032\n",
      "243 1.0634368658065796\n",
      "244 1.0632925033569336\n",
      "245 1.0631482601165771\n",
      "246 1.0630033016204834\n",
      "247 1.0628597736358643\n",
      "248 1.0627176761627197\n",
      "249 1.0625724792480469\n",
      "250 1.0624293088912964\n",
      "251 1.0622851848602295\n",
      "252 1.0621418952941895\n",
      "253 1.0619986057281494\n",
      "254 1.0618542432785034\n",
      "255 1.0617119073867798\n",
      "256 1.061569333076477\n",
      "257 1.0614259243011475\n",
      "258 1.0612832307815552\n",
      "259 1.0611393451690674\n",
      "260 1.0609958171844482\n",
      "261 1.060853362083435\n",
      "262 1.0607105493545532\n",
      "263 1.0605679750442505\n",
      "264 1.0604248046875\n",
      "265 1.0602819919586182\n",
      "266 1.0601389408111572\n",
      "267 1.0599963665008545\n",
      "268 1.0598535537719727\n",
      "269 1.0597115755081177\n",
      "270 1.0595684051513672\n",
      "271 1.059426188468933\n",
      "272 1.05928373336792\n",
      "273 1.0591408014297485\n",
      "274 1.0589988231658936\n",
      "275 1.0588558912277222\n",
      "276 1.0587131977081299\n",
      "277 1.0585708618164062\n",
      "278 1.0584280490875244\n",
      "279 1.058286428451538\n",
      "280 1.0581445693969727\n",
      "281 1.0580017566680908\n",
      "282 1.0578598976135254\n",
      "283 1.05771803855896\n",
      "284 1.0575759410858154\n",
      "285 1.0574342012405396\n",
      "286 1.0572922229766846\n",
      "287 1.0571506023406982\n",
      "288 1.0570094585418701\n",
      "289 1.0568675994873047\n",
      "290 1.056726336479187\n",
      "291 1.0565847158432007\n",
      "292 1.056442141532898\n",
      "293 1.0563007593154907\n",
      "294 1.0561591386795044\n",
      "295 1.0560173988342285\n",
      "296 1.055875301361084\n",
      "297 1.055734395980835\n",
      "298 1.0555938482284546\n",
      "299 1.0554510354995728\n",
      "300 1.0553098917007446\n",
      "301 1.055168867111206\n",
      "302 1.0550274848937988\n",
      "303 1.054887294769287\n",
      "304 1.0547453165054321\n",
      "305 1.0546036958694458\n",
      "306 1.054462194442749\n",
      "307 1.0543212890625\n",
      "308 1.054180383682251\n",
      "309 1.0540393590927124\n",
      "310 1.0538978576660156\n",
      "311 1.0537569522857666\n",
      "312 1.0536164045333862\n",
      "313 1.0534758567810059\n",
      "314 1.0533344745635986\n",
      "315 1.0531941652297974\n",
      "316 1.0530537366867065\n",
      "317 1.052912712097168\n",
      "318 1.0527716875076294\n",
      "319 1.052631139755249\n",
      "320 1.0524903535842896\n",
      "321 1.052349328994751\n",
      "322 1.0522090196609497\n",
      "323 1.0520693063735962\n",
      "324 1.0519285202026367\n",
      "325 1.051788568496704\n",
      "326 1.0516475439071655\n",
      "327 1.0515079498291016\n",
      "328 1.0513674020767212\n",
      "329 1.0512264966964722\n",
      "330 1.05108642578125\n",
      "331 1.0509469509124756\n",
      "332 1.0508071184158325\n",
      "333 1.0506675243377686\n",
      "334 1.0505260229110718\n",
      "335 1.050386667251587\n",
      "336 1.0502465963363647\n",
      "337 1.050106406211853\n",
      "338 1.0499660968780518\n",
      "339 1.0498265027999878\n",
      "340 1.0496875047683716\n",
      "341 1.0495469570159912\n",
      "342 1.0494074821472168\n",
      "343 1.0492671728134155\n",
      "344 1.0491279363632202\n",
      "345 1.0489884614944458\n",
      "346 1.0488487482070923\n",
      "347 1.0487089157104492\n",
      "348 1.0485694408416748\n",
      "349 1.0484302043914795\n",
      "350 1.0482906103134155\n",
      "351 1.0481510162353516\n",
      "352 1.048011064529419\n",
      "353 1.047871708869934\n",
      "354 1.047732949256897\n",
      "355 1.0475927591323853\n",
      "356 1.0474543571472168\n",
      "357 1.0473147630691528\n",
      "358 1.0471751689910889\n",
      "359 1.0470361709594727\n",
      "360 1.0468965768814087\n",
      "361 1.0467578172683716\n",
      "362 1.0466187000274658\n",
      "363 1.0464788675308228\n",
      "364 1.0463401079177856\n",
      "365 1.0462009906768799\n",
      "366 1.0460622310638428\n",
      "367 1.0459237098693848\n",
      "368 1.0457844734191895\n",
      "369 1.0456459522247314\n",
      "370 1.0455067157745361\n",
      "371 1.0453674793243408\n",
      "372 1.045229196548462\n",
      "373 1.0450894832611084\n",
      "374 1.0449507236480713\n",
      "375 1.0448118448257446\n",
      "376 1.044673204421997\n",
      "377 1.04453444480896\n",
      "378 1.044396162033081\n",
      "379 1.0442570447921753\n",
      "380 1.0441186428070068\n",
      "381 1.0439800024032593\n",
      "382 1.0438416004180908\n",
      "383 1.0437029600143433\n",
      "384 1.0435646772384644\n",
      "385 1.043426752090454\n",
      "386 1.0432873964309692\n",
      "387 1.0431501865386963\n",
      "388 1.0430105924606323\n",
      "389 1.042872667312622\n",
      "390 1.0427336692810059\n",
      "391 1.0425958633422852\n",
      "392 1.0424573421478271\n",
      "393 1.0423195362091064\n",
      "394 1.0421810150146484\n",
      "395 1.0420433282852173\n",
      "396 1.0419046878814697\n",
      "397 1.0417670011520386\n",
      "398 1.0416285991668701\n",
      "399 1.0414907932281494\n",
      "400 1.0413535833358765\n",
      "401 1.041215181350708\n",
      "402 1.0410776138305664\n",
      "403 1.040939450263977\n",
      "404 1.0408012866973877\n",
      "405 1.0406635999679565\n",
      "406 1.040526270866394\n",
      "407 1.0403881072998047\n",
      "408 1.0402504205703735\n",
      "409 1.040113091468811\n",
      "410 1.0399757623672485\n",
      "411 1.0398375988006592\n",
      "412 1.0397002696990967\n",
      "413 1.0395619869232178\n",
      "414 1.0394251346588135\n",
      "415 1.0392876863479614\n",
      "416 1.039150595664978\n",
      "417 1.0390130281448364\n",
      "418 1.0388753414154053\n",
      "419 1.038738489151001\n",
      "420 1.0386016368865967\n",
      "421 1.0384641885757446\n",
      "422 1.038326621055603\n",
      "423 1.0381892919540405\n",
      "424 1.0380531549453735\n",
      "425 1.0379157066345215\n",
      "426 1.0377789735794067\n",
      "427 1.0376417636871338\n",
      "428 1.0375049114227295\n",
      "429 1.0373666286468506\n",
      "430 1.0372297763824463\n",
      "431 1.0370938777923584\n",
      "432 1.0369569063186646\n",
      "433 1.0368198156356812\n",
      "434 1.0366828441619873\n",
      "435 1.036547064781189\n",
      "436 1.0364094972610474\n",
      "437 1.0362730026245117\n",
      "438 1.036136507987976\n",
      "439 1.0359997749328613\n",
      "440 1.0358633995056152\n",
      "441 1.0357260704040527\n",
      "442 1.035589575767517\n",
      "443 1.0354533195495605\n",
      "444 1.0353178977966309\n",
      "445 1.035180926322937\n",
      "446 1.0350439548492432\n",
      "447 1.0349081754684448\n",
      "448 1.0347715616226196\n",
      "449 1.0346351861953735\n",
      "450 1.0344982147216797\n",
      "451 1.034362554550171\n",
      "452 1.0342261791229248\n",
      "453 1.0340901613235474\n",
      "454 1.0339534282684326\n",
      "455 1.0338172912597656\n",
      "456 1.0336819887161255\n",
      "457 1.0335454940795898\n",
      "458 1.0334105491638184\n",
      "459 1.0332757234573364\n",
      "460 1.0331394672393799\n",
      "461 1.0330030918121338\n",
      "462 1.0328667163848877\n",
      "463 1.032732367515564\n",
      "464 1.0325967073440552\n",
      "465 1.0324604511260986\n",
      "466 1.032325029373169\n",
      "467 1.032189130783081\n",
      "468 1.0320546627044678\n",
      "469 1.0319182872772217\n",
      "470 1.031783103942871\n",
      "471 1.0316473245620728\n",
      "472 1.031511902809143\n",
      "473 1.031376600265503\n",
      "474 1.031241774559021\n",
      "475 1.0311064720153809\n",
      "476 1.0309709310531616\n",
      "477 1.0308361053466797\n",
      "478 1.0307003259658813\n",
      "479 1.0305651426315308\n",
      "480 1.030429720878601\n",
      "481 1.0302952527999878\n",
      "482 1.030159592628479\n",
      "483 1.0300246477127075\n",
      "484 1.0298893451690674\n",
      "485 1.0297540426254272\n",
      "486 1.0296199321746826\n",
      "487 1.0294846296310425\n",
      "488 1.0293495655059814\n",
      "489 1.029214859008789\n",
      "490 1.029079556465149\n",
      "491 1.0289456844329834\n",
      "492 1.0288105010986328\n",
      "493 1.0286753177642822\n",
      "494 1.028541088104248\n",
      "495 1.0284059047698975\n",
      "496 1.028271198272705\n",
      "497 1.0281364917755127\n",
      "498 1.0280015468597412\n",
      "499 1.0278677940368652\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-4\n",
    "for t in range(500):\n",
    "    # Forward pass: compute predicted y by passing x to the model. Module objects\n",
    "    # override the __call__ operator so you can call them like functions. When\n",
    "    # doing so you pass a Tensor of input data to the Module and it produces\n",
    "    # a Tensor of output data.\n",
    "    y_pred = forward_fn(x)\n",
    "\n",
    "    # Compute and print loss. We pass Tensors containing the predicted and true\n",
    "    # values of y, and the loss function returns a Tensor containing the\n",
    "    # loss.\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    print(t, loss.item())\n",
    "\n",
    "    # Zero the gradients before running the backward pass.\n",
    "    forward_fn.zero_grad()\n",
    "\n",
    "    # Backward pass: compute gradient of the loss with respect to all the learnable\n",
    "    # parameters of the model. Internally, the parameters of each Module are stored\n",
    "    # in Tensors with requires_grad=True, so this call will compute gradients for\n",
    "    # all learnable parameters in the model.\n",
    "    loss.backward()\n",
    "\n",
    "    # Update the weights using gradient descent. Each parameter is a Tensor, so\n",
    "    # we can access its gradients like we did before.\n",
    "    with tc.no_grad():\n",
    "        for param in forward_fn.parameters():\n",
    "            param -= learning_rate * param.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using __torch.optim__ to simplify the result, the training above is equivalent to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1.027732253074646\n",
      "1 1.0010449886322021\n",
      "2 0.9753431081771851\n",
      "3 0.950370192527771\n",
      "4 0.9262723922729492\n",
      "5 0.9028702974319458\n",
      "6 0.8800479173660278\n",
      "7 0.857866644859314\n",
      "8 0.8363658785820007\n",
      "9 0.8154324293136597\n",
      "10 0.795068621635437\n",
      "11 0.775452196598053\n",
      "12 0.7563856840133667\n",
      "13 0.7378247380256653\n",
      "14 0.7198775410652161\n",
      "15 0.7025035619735718\n",
      "16 0.6856686472892761\n",
      "17 0.669363260269165\n",
      "18 0.6535362601280212\n",
      "19 0.6381906270980835\n",
      "20 0.6231862306594849\n",
      "21 0.6085701584815979\n",
      "22 0.5943557024002075\n",
      "23 0.5804651975631714\n",
      "24 0.5669506192207336\n",
      "25 0.5538226366043091\n",
      "26 0.5411171317100525\n",
      "27 0.528744637966156\n",
      "28 0.5166839361190796\n",
      "29 0.50486820936203\n",
      "30 0.49325594305992126\n",
      "31 0.4818821847438812\n",
      "32 0.47078990936279297\n",
      "33 0.45995187759399414\n",
      "34 0.4493201673030853\n",
      "35 0.438931405544281\n",
      "36 0.4287474751472473\n",
      "37 0.4187738299369812\n",
      "38 0.40901821851730347\n",
      "39 0.3994709253311157\n",
      "40 0.39015042781829834\n",
      "41 0.38099151849746704\n",
      "42 0.37201666831970215\n",
      "43 0.363247811794281\n",
      "44 0.354663610458374\n",
      "45 0.3462325930595398\n",
      "46 0.33796173334121704\n",
      "47 0.3298453688621521\n",
      "48 0.3218840956687927\n",
      "49 0.3140907287597656\n",
      "50 0.30646640062332153\n",
      "51 0.29899975657463074\n",
      "52 0.29170697927474976\n",
      "53 0.28457021713256836\n",
      "54 0.2775868773460388\n",
      "55 0.2707371115684509\n",
      "56 0.2640342116355896\n",
      "57 0.2574766278266907\n",
      "58 0.2510533034801483\n",
      "59 0.2447531670331955\n",
      "60 0.23856620490550995\n",
      "61 0.23249836266040802\n",
      "62 0.22655227780342102\n",
      "63 0.2207373082637787\n",
      "64 0.21506337821483612\n",
      "65 0.2095053493976593\n",
      "66 0.2040669173002243\n",
      "67 0.19874681532382965\n",
      "68 0.19354236125946045\n",
      "69 0.1884341537952423\n",
      "70 0.1834307461977005\n",
      "71 0.17853227257728577\n",
      "72 0.17374730110168457\n",
      "73 0.16905997693538666\n",
      "74 0.1644720733165741\n",
      "75 0.15999600291252136\n",
      "76 0.15562601387500763\n",
      "77 0.15134987235069275\n",
      "78 0.14716503024101257\n",
      "79 0.14307406544685364\n",
      "80 0.13907921314239502\n",
      "81 0.1351727992296219\n",
      "82 0.13136127591133118\n",
      "83 0.1276288479566574\n",
      "84 0.12398003041744232\n",
      "85 0.12042604386806488\n",
      "86 0.11696787178516388\n",
      "87 0.1135883778333664\n",
      "88 0.11028750985860825\n",
      "89 0.10706882178783417\n",
      "90 0.10393043607473373\n",
      "91 0.1008661538362503\n",
      "92 0.09787441045045853\n",
      "93 0.09495876729488373\n",
      "94 0.09211469441652298\n",
      "95 0.08933704346418381\n",
      "96 0.0866343304514885\n",
      "97 0.08399777859449387\n",
      "98 0.08143305033445358\n",
      "99 0.07893235981464386\n",
      "100 0.07649998366832733\n",
      "101 0.07412891089916229\n",
      "102 0.07181902229785919\n",
      "103 0.06957363337278366\n",
      "104 0.06738580763339996\n",
      "105 0.06525856256484985\n",
      "106 0.06318879127502441\n",
      "107 0.06117381900548935\n",
      "108 0.05921750143170357\n",
      "109 0.05731542780995369\n",
      "110 0.05546547845005989\n",
      "111 0.05366845801472664\n",
      "112 0.05192508548498154\n",
      "113 0.05022749304771423\n",
      "114 0.0485786609351635\n",
      "115 0.04697754234075546\n",
      "116 0.04542180523276329\n",
      "117 0.043910227715969086\n",
      "118 0.04244071617722511\n",
      "119 0.04101622477173805\n",
      "120 0.03963153809309006\n",
      "121 0.038287874311208725\n",
      "122 0.036987029016017914\n",
      "123 0.035723358392715454\n",
      "124 0.03450082987546921\n",
      "125 0.033312611281871796\n",
      "126 0.03216110169887543\n",
      "127 0.031044786795973778\n",
      "128 0.02996267005801201\n",
      "129 0.028913628309965134\n",
      "130 0.027898874133825302\n",
      "131 0.02691691182553768\n",
      "132 0.025965431705117226\n",
      "133 0.02504541352391243\n",
      "134 0.02415524423122406\n",
      "135 0.023294800892472267\n",
      "136 0.022462181746959686\n",
      "137 0.02165742963552475\n",
      "138 0.020878612995147705\n",
      "139 0.020125586539506912\n",
      "140 0.0193985253572464\n",
      "141 0.0186957698315382\n",
      "142 0.018017232418060303\n",
      "143 0.017362451180815697\n",
      "144 0.016729071736335754\n",
      "145 0.01611899584531784\n",
      "146 0.015528944320976734\n",
      "147 0.014959934167563915\n",
      "148 0.014410780742764473\n",
      "149 0.01388025563210249\n",
      "150 0.013368603773415089\n",
      "151 0.012875504791736603\n",
      "152 0.012398865073919296\n",
      "153 0.011939872987568378\n",
      "154 0.011496784165501595\n",
      "155 0.01106998510658741\n",
      "156 0.010658709332346916\n",
      "157 0.010262463241815567\n",
      "158 0.009879388846457005\n",
      "159 0.009510966017842293\n",
      "160 0.009156188927590847\n",
      "161 0.008813509717583656\n",
      "162 0.008483519777655602\n",
      "163 0.008165375329554081\n",
      "164 0.007859129458665848\n",
      "165 0.007563988212496042\n",
      "166 0.0072800153866410255\n",
      "167 0.007007342763245106\n",
      "168 0.006744746118783951\n",
      "169 0.006491736508905888\n",
      "170 0.006248490884900093\n",
      "171 0.006013975944370031\n",
      "172 0.0057884277775883675\n",
      "173 0.0055711171589791775\n",
      "174 0.005362085532397032\n",
      "175 0.005160832777619362\n",
      "176 0.004967209417372942\n",
      "177 0.004780733026564121\n",
      "178 0.0046011232770979404\n",
      "179 0.004428507760167122\n",
      "180 0.0042622811160981655\n",
      "181 0.0041023483499884605\n",
      "182 0.003948277328163385\n",
      "183 0.0038000955246388912\n",
      "184 0.0036574359983205795\n",
      "185 0.0035200673155486584\n",
      "186 0.0033878509420901537\n",
      "187 0.0032606187742203474\n",
      "188 0.003138197585940361\n",
      "189 0.003020252799615264\n",
      "190 0.002906802576035261\n",
      "191 0.0027976094279438257\n",
      "192 0.002692471956834197\n",
      "193 0.002591195981949568\n",
      "194 0.002493742387741804\n",
      "195 0.002399880439043045\n",
      "196 0.0023095232900232077\n",
      "197 0.0022225799039006233\n",
      "198 0.002138749696314335\n",
      "199 0.0020580494310706854\n",
      "200 0.001980400178581476\n",
      "201 0.0019056927412748337\n",
      "202 0.0018337059300392866\n",
      "203 0.0017644064500927925\n",
      "204 0.0016976933693513274\n",
      "205 0.0016333900857716799\n",
      "206 0.0015715556219220161\n",
      "207 0.0015119957970455289\n",
      "208 0.0014546237653121352\n",
      "209 0.0013993855100125074\n",
      "210 0.0013462248025462031\n",
      "211 0.0012949720257893205\n",
      "212 0.0012456543045118451\n",
      "213 0.0011981487041339278\n",
      "214 0.0011523994617164135\n",
      "215 0.001108529046177864\n",
      "216 0.0010662840213626623\n",
      "217 0.0010256122332066298\n",
      "218 0.000986431143246591\n",
      "219 0.0009487209608778358\n",
      "220 0.0009124002535827458\n",
      "221 0.0008774197776801884\n",
      "222 0.00084373087156564\n",
      "223 0.0008112982613965869\n",
      "224 0.0007800667663104832\n",
      "225 0.0007499873172491789\n",
      "226 0.0007210220210254192\n",
      "227 0.0006931284442543983\n",
      "228 0.0006662566447630525\n",
      "229 0.0006403886363841593\n",
      "230 0.0006154906586743891\n",
      "231 0.0005915009533055127\n",
      "232 0.0005684054922312498\n",
      "233 0.0005461688851937652\n",
      "234 0.0005247652297839522\n",
      "235 0.0005041509866714478\n",
      "236 0.000484308140585199\n",
      "237 0.00046521579497493804\n",
      "238 0.00044682490988634527\n",
      "239 0.00042912160279229283\n",
      "240 0.00041208998300135136\n",
      "241 0.0003957098815590143\n",
      "242 0.00037991924909874797\n",
      "243 0.00036476951208896935\n",
      "244 0.0003501162282191217\n",
      "245 0.00033604929922148585\n",
      "246 0.0003225106920581311\n",
      "247 0.00030948169296607375\n",
      "248 0.000296948739560321\n",
      "249 0.0002848885487765074\n",
      "250 0.00027328947908245027\n",
      "251 0.00026213034288957715\n",
      "252 0.00025140115758404136\n",
      "253 0.00024108118668664247\n",
      "254 0.00023117149248719215\n",
      "255 0.0002216266730101779\n",
      "256 0.00021245919924695045\n",
      "257 0.00020364648662507534\n",
      "258 0.0001951793092302978\n",
      "259 0.00018704295507632196\n",
      "260 0.00017922595725394785\n",
      "261 0.00017171443323604763\n",
      "262 0.00016450035036541522\n",
      "263 0.0001575723581481725\n",
      "264 0.00015091821842361242\n",
      "265 0.0001445304515073076\n",
      "266 0.00013839500024914742\n",
      "267 0.0001325065386481583\n",
      "268 0.00012685362889897078\n",
      "269 0.00012142890773247927\n",
      "270 0.00011622338934103027\n",
      "271 0.00011122944124508649\n",
      "272 0.00010643529094522819\n",
      "273 0.00010183799167862162\n",
      "274 9.742837573867291e-05\n",
      "275 9.319985110778362e-05\n",
      "276 8.914415229810402e-05\n",
      "277 8.525582234142348e-05\n",
      "278 8.152893133228645e-05\n",
      "279 7.795579585945234e-05\n",
      "280 7.453132275259122e-05\n",
      "281 7.124988042050973e-05\n",
      "282 6.810983904870227e-05\n",
      "283 6.50941365165636e-05\n",
      "284 6.220887007657439e-05\n",
      "285 5.944579606875777e-05\n",
      "286 5.6801487517077476e-05\n",
      "287 5.4265699873212725e-05\n",
      "288 5.1839753723470494e-05\n",
      "289 4.9517278966959566e-05\n",
      "290 4.7294153773691505e-05\n",
      "291 4.516613989835605e-05\n",
      "292 4.312989040045068e-05\n",
      "293 4.118312062928453e-05\n",
      "294 3.9317998016485944e-05\n",
      "295 3.7534911825787276e-05\n",
      "296 3.5829358239425346e-05\n",
      "297 3.4198197681689635e-05\n",
      "298 3.2638872653478757e-05\n",
      "299 3.114659193670377e-05\n",
      "300 2.9720680686295964e-05\n",
      "301 2.8357553674140945e-05\n",
      "302 2.7054644306190312e-05\n",
      "303 2.5809413273236714e-05\n",
      "304 2.4619332180009224e-05\n",
      "305 2.3482029064325616e-05\n",
      "306 2.2395941414288245e-05\n",
      "307 2.13583443837706e-05\n",
      "308 2.0367117031128146e-05\n",
      "309 1.9420500393607654e-05\n",
      "310 1.8516539057600312e-05\n",
      "311 1.7653317627264187e-05\n",
      "312 1.6829049855004996e-05\n",
      "313 1.6042922652559355e-05\n",
      "314 1.5293742762878537e-05\n",
      "315 1.4578698028344661e-05\n",
      "316 1.3896262316848151e-05\n",
      "317 1.324442018812988e-05\n",
      "318 1.2622028407349717e-05\n",
      "319 1.2027579941786826e-05\n",
      "320 1.1461494977993425e-05\n",
      "321 1.091857939172769e-05\n",
      "322 1.0401635336165782e-05\n",
      "323 9.908393622026779e-06\n",
      "324 9.437796506972518e-06\n",
      "325 8.988643457996659e-06\n",
      "326 8.560369678889401e-06\n",
      "327 8.151911970344372e-06\n",
      "328 7.7623099059565e-06\n",
      "329 7.39075676392531e-06\n",
      "330 7.036672286631074e-06\n",
      "331 6.6989691731578205e-06\n",
      "332 6.377158570103347e-06\n",
      "333 6.070427389204269e-06\n",
      "334 5.777981186838588e-06\n",
      "335 5.499441158463014e-06\n",
      "336 5.233972842688672e-06\n",
      "337 4.981030087947147e-06\n",
      "338 4.7400199036928825e-06\n",
      "339 4.510464350460097e-06\n",
      "340 4.291792265576078e-06\n",
      "341 4.083526619069744e-06\n",
      "342 3.885159912897507e-06\n",
      "343 3.6962276226404356e-06\n",
      "344 3.5163034226570744e-06\n",
      "345 3.345038294355618e-06\n",
      "346 3.1817871786188334e-06\n",
      "347 3.0264657198131317e-06\n",
      "348 2.8785757422156166e-06\n",
      "349 2.7377514015825e-06\n",
      "350 2.603754865049268e-06\n",
      "351 2.476126383044175e-06\n",
      "352 2.3546629108750494e-06\n",
      "353 2.239034756712499e-06\n",
      "354 2.1289838514348958e-06\n",
      "355 2.0242398477421375e-06\n",
      "356 1.9245617295382544e-06\n",
      "357 1.8297147335033515e-06\n",
      "358 1.7394335145581863e-06\n",
      "359 1.6535368558834307e-06\n",
      "360 1.5718178474344313e-06\n",
      "361 1.4940326309442753e-06\n",
      "362 1.4200610394254909e-06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363 1.349674789707933e-06\n",
      "364 1.2827576938434504e-06\n",
      "365 1.2190541838208446e-06\n",
      "366 1.1584746744119911e-06\n",
      "367 1.1008562523784349e-06\n",
      "368 1.0460435078130104e-06\n",
      "369 9.939418532667332e-07\n",
      "370 9.443667181585624e-07\n",
      "371 8.972216392066912e-07\n",
      "372 8.524084478267469e-07\n",
      "373 8.097885029201279e-07\n",
      "374 7.692772783229884e-07\n",
      "375 7.307468763428915e-07\n",
      "376 6.941174319763377e-07\n",
      "377 6.593020316358889e-07\n",
      "378 6.261908538363059e-07\n",
      "379 5.947277941231732e-07\n",
      "380 5.64807805858436e-07\n",
      "381 5.363642117117706e-07\n",
      "382 5.09339429299871e-07\n",
      "383 4.836655307371984e-07\n",
      "384 4.592567961481109e-07\n",
      "385 4.360378227374895e-07\n",
      "386 4.1399593442292826e-07\n",
      "387 3.9305095356212405e-07\n",
      "388 3.731342985702213e-07\n",
      "389 3.5421530242274457e-07\n",
      "390 3.362455345268245e-07\n",
      "391 3.191712210082187e-07\n",
      "392 3.02939980656447e-07\n",
      "393 2.87521743302932e-07\n",
      "394 2.7287762804917293e-07\n",
      "395 2.5897435307342676e-07\n",
      "396 2.457585708270926e-07\n",
      "397 2.3320717446040362e-07\n",
      "398 2.2127241550151666e-07\n",
      "399 2.0994782801153633e-07\n",
      "400 1.9919218630093383e-07\n",
      "401 1.8897884501711815e-07\n",
      "402 1.7927675344253657e-07\n",
      "403 1.7006284735998634e-07\n",
      "404 1.6132001690039033e-07\n",
      "405 1.5300622635550098e-07\n",
      "406 1.451339102231941e-07\n",
      "407 1.3762937101091666e-07\n",
      "408 1.3052337521912705e-07\n",
      "409 1.2378497160625557e-07\n",
      "410 1.173695522993512e-07\n",
      "411 1.1129252186492522e-07\n",
      "412 1.055181400033689e-07\n",
      "413 1.0003176242889822e-07\n",
      "414 9.483979113156238e-08\n",
      "415 8.989739797016227e-08\n",
      "416 8.521169547748286e-08\n",
      "417 8.076634827602902e-08\n",
      "418 7.654627864894792e-08\n",
      "419 7.25423632275124e-08\n",
      "420 6.874416413893414e-08\n",
      "421 6.51436451448717e-08\n",
      "422 6.172355426770082e-08\n",
      "423 5.847564210625933e-08\n",
      "424 5.540022129935096e-08\n",
      "425 5.2479105505653934e-08\n",
      "426 4.9709996119418065e-08\n",
      "427 4.7085727317153214e-08\n",
      "428 4.459401026224441e-08\n",
      "429 4.2229892471823405e-08\n",
      "430 3.9995903478029504e-08\n",
      "431 3.786860602872366e-08\n",
      "432 3.585544661177664e-08\n",
      "433 3.394602998696428e-08\n",
      "434 3.2133694816138814e-08\n",
      "435 3.041495233446767e-08\n",
      "436 2.879174942904683e-08\n",
      "437 2.7250900203057427e-08\n",
      "438 2.5788001067894584e-08\n",
      "439 2.4402799780887108e-08\n",
      "440 2.309040247894245e-08\n",
      "441 2.1847153419685128e-08\n",
      "442 2.066934357003447e-08\n",
      "443 1.9552862440264107e-08\n",
      "444 1.8492828601779365e-08\n",
      "445 1.7492908455096767e-08\n",
      "446 1.654164449860218e-08\n",
      "447 1.5642948270055967e-08\n",
      "448 1.4793090308273804e-08\n",
      "449 1.3986524827203084e-08\n",
      "450 1.3222420491842968e-08\n",
      "451 1.249862968677462e-08\n",
      "452 1.1814197620196865e-08\n",
      "453 1.1166538804729953e-08\n",
      "454 1.0553530493950802e-08\n",
      "455 9.972508152600312e-09\n",
      "456 9.421449398416826e-09\n",
      "457 8.900681969237212e-09\n",
      "458 8.409278606791304e-09\n",
      "459 7.943684821043462e-09\n",
      "460 7.5032655644236e-09\n",
      "461 7.085327435873978e-09\n",
      "462 6.690787923702146e-09\n",
      "463 6.318848555508794e-09\n",
      "464 5.966485527864052e-09\n",
      "465 5.631078270340595e-09\n",
      "466 5.315586193432864e-09\n",
      "467 5.017061432965875e-09\n",
      "468 4.7350159348980014e-09\n",
      "469 4.467876735247955e-09\n",
      "470 4.215743754087953e-09\n",
      "471 3.978320783915024e-09\n",
      "472 3.752453903160813e-09\n",
      "473 3.539912585281968e-09\n",
      "474 3.337962350968837e-09\n",
      "475 3.148141747288946e-09\n",
      "476 2.968814527548602e-09\n",
      "477 2.7987401285400892e-09\n",
      "478 2.6384663343037573e-09\n",
      "479 2.4879269755473388e-09\n",
      "480 2.3442754404356947e-09\n",
      "481 2.2097617069505304e-09\n",
      "482 2.0828059277278044e-09\n",
      "483 1.9617527602378004e-09\n",
      "484 1.8483149455406078e-09\n",
      "485 1.741464972226936e-09\n",
      "486 1.6401371372154472e-09\n",
      "487 1.5447664258871896e-09\n",
      "488 1.4543888315898812e-09\n",
      "489 1.3696517253691809e-09\n",
      "490 1.2897969359215722e-09\n",
      "491 1.214466083254706e-09\n",
      "492 1.1425742574289188e-09\n",
      "493 1.074767275177635e-09\n",
      "494 1.012045780512949e-09\n",
      "495 9.519004473546033e-10\n",
      "496 8.962143249746646e-10\n",
      "497 8.427917252973316e-10\n",
      "498 7.929411016682764e-10\n",
      "499 7.454278860841157e-10\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-4\n",
    "optimizer = tc.optim.Adam(forward_fn.parameters(), lr=learning_rate)\n",
    "for t in range(500):\n",
    "    y_pred = forward_fn(x)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    print(t, loss.item())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "\n",
    "    # Calling the step function on an Optimizer makes an update to its\n",
    "    # parameters\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training  CNN on MNIST\n",
    "Step 0: load data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    train_data = tv.datasets.MNIST(root='data/mnist', train=True,\n",
    "                                            transform=tv.transforms.ToTensor(),\n",
    "                                            download=True)\n",
    "    test_data = tv.datasets.MNIST(root='data/mnist', train=False,\n",
    "                                            transform=tv.transforms.ToTensor(),\n",
    "                                            download=True)\n",
    "    return train_data, test_data\n",
    "\n",
    "def imshow(instance, label):\n",
    "    plt.imshow(instance.reshape(28,28), cmap='gray')\n",
    "    plt.title('%i' % label, fontsize = 20)\n",
    "    plt.show()\n",
    "\n",
    "train_data, test_data = load_data()\n",
    "X_test = test_data.test_data.reshape(10000,1,28,28)\n",
    "X_test = tc.tensor(X_test,dtype=tc.float) / 255\n",
    "y_test = test_data.test_labels\n",
    "import torch.utils.data as Data\n",
    "train_batch = Data.DataLoader(dataset=train_data, batch_size=100,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow(X_test[1], y_test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: define forward function\n",
    "\n",
    "    layer 1: Convolutional + Relu + Maxpooling\n",
    "    layer 2: Convolutional + Relu + Maxpooling\n",
    "    layer 3: linear\n",
    "    \n",
    "reference:\n",
    "Conv2d:https://pytorch.org/docs/stable/nn.html?highlight=conv#torch.nn.functional.conv2d\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = tc.nn\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1_conv = nn.Sequential(  # input shape (1, 28, 28)\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,      # input height\n",
    "                out_channels=16,    # n_filters\n",
    "                kernel_size=5,      # filter size\n",
    "                stride=1,           # filter movement/step\n",
    "                padding=2,      # å¦‚æžœæƒ³è¦ con2d å‡ºæ¥çš„å›¾ç‰‡é•¿å®½æ²¡æœ‰å˜åŒ–, padding=(kernel_size-1)/2 å½“ stride=1\n",
    "            ),      # output shape (16, 28, 28)\n",
    "            nn.ReLU(),    # activation\n",
    "            nn.MaxPool2d(kernel_size=2),    # åœ¨ 2x2 ç©ºé—´é‡Œå‘ä¸‹é‡‡æ ·, output shape (16, 14, 14)\n",
    "        )\n",
    "        self.layer2_conv = nn.Sequential(  # input shape (1, 28, 28)\n",
    "            nn.Conv2d(16, 32, 5, 1, 2),  # output shape (32, 14, 14)\n",
    "            nn.ReLU(),  # activation\n",
    "            nn.MaxPool2d(2),  # output shape (32, 7, 7)\n",
    "        )\n",
    "        self.layer3_linear = nn.Linear(32 * 7 * 7, 10)   # fully connected layer, output 10 classes\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.layer1_conv(x)\n",
    "        x = self.layer2_conv(x)\n",
    "        x = x.view(x.size(0), -1)   # å±•å¹³å¤šç»´çš„å·ç§¯å›¾æˆ (batch_size, 32 * 7 * 7)\n",
    "        output = self.layer3_linear(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: define loss\n",
    "\n",
    "cross entropy:\n",
    "    https://pytorch.org/docs/stable/nn.html?highlight=cross%20entropy#torch.nn.functional.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_mnist = CNN()\n",
    "optimizer = tc.optim.Adam(cnn_mnist.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training, several consideration are needed:\n",
    "1. how many round? how big is the batch each time?\n",
    "```\n",
    "    for each_round in epoch:\n",
    "        for each_example in  example:\n",
    "```\n",
    "2. what about testing set?\n",
    "3. what about logging?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 |Step: 0 |train loss:0.2742 |test accuracy:0.9357\n",
      "Epoch: 0 |Step: 100 |train loss:0.2296 |test accuracy:0.9615\n",
      "Epoch: 0 |Step: 200 |train loss:0.0503 |test accuracy:0.9643\n",
      "Epoch: 0 |Step: 300 |train loss:0.0928 |test accuracy:0.9720\n",
      "Epoch: 0 |Step: 400 |train loss:0.1112 |test accuracy:0.9772\n",
      "Epoch: 0 |Step: 500 |train loss:0.0583 |test accuracy:0.9808\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1):\n",
    "    for step, (x, y) in enumerate(train_batch):\n",
    "        output = cnn_mnist(x)\n",
    "        loss = loss_func(output, y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    " \n",
    "        if step % 100 == 0:\n",
    "            outputs = cnn_mnist(X_test)\n",
    "            _, predicted = tc.max(outputs.data, 1)\n",
    "            total = y_test.size(0)\n",
    "            correct = (predicted == y_test).sum().item()\n",
    "            accuracy = correct/total\n",
    "            print('Epoch:', epoch, '|Step:', step,\n",
    "                  '|train loss:%.4f' % loss.data.item(), '|test accuracy:%.4f' % accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cifar10?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "  cat  deer plane  frog\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#release memory\n",
    "import gc\n",
    "del train_data\n",
    "del test_data\n",
    "gc.collect()\n",
    "\n",
    "transform = tv.transforms.Compose(\n",
    "    [tv.transforms.ToTensor(),\n",
    "     tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = tv.datasets.CIFAR10(root='data/cifar10', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = tc.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = tv.datasets.CIFAR10(root='data/cifar10', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = tc.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(tv.utils.make_grid(images))\n",
    "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
